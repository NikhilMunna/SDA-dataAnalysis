{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all required imports\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "import statistics\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "collist = ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11', 'feature_12', 'feature_13', 'feature_14', 'feature_15', 'feature_16', 'feature_17', 'feature_18', 'feature_19', 'feature_20', 'feature_21', 'feature_22', 'feature_23', 'feature_24', 'feature_25', 'feature_26', 'feature_27', 'feature_28', 'feature_29', 'feature_30', 'feature_31', 'feature_32', 'feature_33', 'feature_34', 'feature_35', 'feature_36', 'feature_37', 'feature_38', 'feature_39', 'feature_40', 'feature_41', 'feature_42', 'feature_43', 'feature_44', 'feature_45', 'feature_46', 'feature_47', 'feature_48', 'feature_49', 'feature_50', 'feature_51', 'feature_52', 'feature_53', 'feature_54', 'feature_55', 'feature_56', 'feature_57', 'feature_58', 'feature_59', 'feature_60', 'feature_61', 'feature_62', 'feature_63', 'feature_64', 'feature_65', 'feature_66', 'feature_67', 'feature_68', 'feature_69', 'feature_70', 'feature_71', 'feature_72', 'feature_73', 'feature_74', 'feature_75', 'feature_76', 'feature_77', 'feature_78', 'feature_79', 'feature_80', 'feature_81', 'feature_82', 'feature_83', 'feature_84', 'feature_85', 'feature_86', 'feature_87', 'feature_88', 'feature_89', 'feature_90', 'feature_91', 'feature_92', 'feature_93', 'feature_94', 'feature_95', 'feature_96', 'feature_97', 'feature_98', 'feature_99', 'feature_100', 'feature_101', 'feature_102', 'feature_103', 'feature_104', 'feature_105', 'feature_106', 'feature_107', 'feature_108', 'feature_109', 'feature_110', 'feature_111', 'feature_112', 'feature_113', 'feature_114', 'feature_115', 'feature_116','latitude','longitude']\n",
    "\n",
    "data = pd.read_csv(\"./dataset/default_plus_chromatic_features_1059_tracks (copy).csv\",names = collist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1059 entries, 0 to 1058\n",
      "Columns: 118 entries, feature_1 to longitude\n",
      "dtypes: float64(118)\n",
      "memory usage: 976.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = data._get_numeric_data().columns\n",
    "print(\"Numerical Columns\",num_cols)\n",
    "cat_cols=list(set(data.columns) - set(num_cols))\n",
    "print(\"Categorical Columns:\",cat_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_scores = np.abs(stats.zscore(data))\n",
    "\n",
    "threshold =3\n",
    "\n",
    "print(np.where(z_scores > 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(data[\"latitude\"], data[\"longitude\"])\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data = data[(z_scores < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(refined_data[\"latitude\"], refined_data[\"longitude\"])\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IQR \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iqr = data[~((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iqr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "ax.scatter(data_iqr[\"latitude\"], data_iqr[\"longitude\"])\n",
    "ax.set_xlabel('Latitude')\n",
    "ax.set_ylabel('Longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = data.iloc[:, 0:116].values\n",
    "y = data.iloc[:,116:118].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 33\n",
    "kmeans = KMeans(n_clusters=n_clusters, max_iter = 500, algorithm='full')\n",
    "kmeans = kmeans.fit(y)\n",
    "labels = kmeans.predict(y)\n",
    "centroids = kmeans.cluster_centers_\n",
    "print(centroids)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_color = [matplotlib.cm.nipy_spectral(float(l) /n_clusters) for l in labels]\n",
    "plt.scatter(y[:, 1], y[:, 0], c = label_color, s=25)\n",
    "plt.title(\"Clustered regions by coordinates\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "plt.rcParams[\"figure.figsize\"] = (20,5)\n",
    "\n",
    "dbs = DBSCAN(eps=3, min_samples=2).fit(y)\n",
    "core_samples_mask = np.zeros_like(dbs.labels_, dtype=bool)\n",
    "core_samples_mask[dbs.core_sample_indices_] = True\n",
    "dbs_labels = dbs.labels_\n",
    "\n",
    "n_clusters_ = len(set(dbs_labels)) - (1 if -1 in dbs_labels else 0)\n",
    "n_noise_ = list(dbs_labels).count(-1)\n",
    "print(n_clusters_\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set(labels)\n",
    "colors = [plt.cm.Spectral(each)\n",
    "          for each in np.linspace(0, 1, len(unique_labels))]\n",
    "for k, col in zip(unique_labels, colors):\n",
    "    if k == -1:\n",
    "        # Black used for noise.\n",
    "        col = [0, 0, 0, 1]\n",
    "\n",
    "    class_member_mask = (labels == k)\n",
    "\n",
    "    xy = X[class_member_mask & core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=14)\n",
    "\n",
    "    xy = X[class_member_mask & ~core_samples_mask]\n",
    "    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),\n",
    "             markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title('Estimated number of clusters: %d' % n_clusters_)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from factor_analyzer import FactorAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df + +0.00001*np.random.rand(1059, 118)\n",
    "fa = FactorAnalyzer(rotation = None)\n",
    "fa.fit(df)\n",
    "# Check Eigenvalues\n",
    "ev, v = fa.get_eigenvalues()\n",
    "ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df\n",
    "plt.scatter(range(1,df.shape[1]+1),ev)\n",
    "plt.plot(range(1,df.shape[1]+1),ev)\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Factors')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = FactorAnalyzer(n_factors = 20,rotation = \"varimax\")\n",
    "fa.fit(df)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.loadings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa.get_factor_variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np \n",
    "import statsmodels.api as sm \n",
    "import pylab as py \n",
    "  \n",
    "# np.random generates different random numbers \n",
    "# whenever the code is executed \n",
    "# Note: When you execute the same code  \n",
    "# the graph look different than shown below. \n",
    "  \n",
    "# Random data points generated \n",
    "# data_points = np.random.normal(0, 1, 100)     \n",
    "  \n",
    "sm.qqplot(data[\"feature_4\"], line ='45') \n",
    "py.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(data[\"feature_5\"], line ='45') \n",
    "py.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(data[\"feature_25\"], line ='45') \n",
    "py.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(data[\"feature_65\"], line ='45') \n",
    "py.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"feature_1\"] , bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"feature_19\"] , bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"feature_63\"] , bins =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data[\"feature_45\"] , bins =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(data[\"feature_38\"] , bins =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import pearsonr\n",
    "sample1 = data.sample(frac=0.5, replace=True, random_state=1)\n",
    "sample2 = data.sample(frac=0.5, replace=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr , p = pearsonr(sample1[\"feature_1\"] ,sample2[\"feature_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "stat, p = ttest_rel(sample1, sample2)\n",
    "if p.all() > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Variance Test (ANOVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "stat, p = f_oneway(sample1, sample2)\n",
    "# print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p.all() > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for Equal variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "levene(sample1[\"feature_1\"],sample2[\"feature_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(848, 116)\n",
      "(211, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.8, random_state=1234)\n",
    "\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "\n",
    "\n",
    "scaled_Xtrain = X_scaler.transform(Xtrain)\n",
    "scaler = StandardScaler()\n",
    "scaled_Xtest = X_scaler.transform(Xtest)\n",
    "print(scaled_Xtest.shape)\n",
    "print(ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "# from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCA_var = PCA(n_components = X_scaler.transform(X).shape[1])\n",
    "PCA_var.fit(X_scaler.transform(X))\n",
    "PCA_var_exp = [1 - x/sum(PCA_var.explained_variance_) for x in PCA_var.explained_variance_]\n",
    "\n",
    "PCA_var_exp.insert(0, 0)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"PCA variance explained over number of PCs\")\n",
    "plt.xlabel(\"Number of PCs\")\n",
    "plt.ylabel(\"Ratio of variance explained\")\n",
    "plt.plot(range(0, len(PCA_var_exp), 1), PCA_var_exp, c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (847, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0155e47a3976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mrfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features_to_select\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_comps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_Xtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_Xtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mrfe_best_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn_comps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \"\"\"\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/feature_selection/rfe.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, step_score)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# self.scores_ will not be calculated when calling _fit through fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;31m# Initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    722\u001b[0m                         dtype=None)\n\u001b[1;32m    723\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (847, 2)"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import learning_curve, ParameterGrid\n",
    "# from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "estimators = {}\n",
    "\n",
    "estimators['svc'] = SVC\n",
    "estimators['rfc'] = RandomForestClassifier\n",
    "estimators['logreg'] = LogisticRegression\n",
    "\n",
    "params = {}\n",
    "params['svc'] = {'kernel': ['linear'], 'C': [10**x for x in range(-1, 3, 1)], \n",
    "                 'gamma': [10**x for x in range(-1, 2, 1)], \n",
    "                'random_state': [1234]}\n",
    "params['rfc'] = {'n_estimators': [5*x for x in range(3, 5, 1)]}\n",
    "\n",
    "params['logreg'] = {'C': [10**x for x in range(-1, 3, 1)], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "rfe_best_model = {}\n",
    "pca_best_model = {}\n",
    "                          \n",
    "\n",
    "for i, estimator in enumerate(estimators):\n",
    "    model_params = ParameterGrid(params[estimator])\n",
    "    grid = model_params\n",
    "    \n",
    "    rfe_best_model[estimator] = []\n",
    "    pca_best_model[estimator] = []\n",
    "    \n",
    "    for n_comps in range(1, scaled_Xtrain.shape[1], 1):\n",
    "        rfe_best_model[estimator].append(0)\n",
    "        pca_best_model[estimator].append(0)\n",
    "            \n",
    "        for params_combo in grid:\n",
    "        \n",
    "            estimator_iter = estimators[estimator]\n",
    "            estimator_iter = estimator_iter(**params_combo)\n",
    "\n",
    "            rfe = RFE(estimator = estimator_iter, n_features_to_select=n_comps)\n",
    "            rfe.fit(scaled_Xtrain, ytrain)\n",
    "\n",
    "            if (rfe.score(scaled_Xtest, ytest) > rfe_best_model[estimator][n_comps - 1]):\n",
    "                rfe_best_model[estimator][n_comps - 1] = rfe.score(scaled_Xtest, ytest)\n",
    "                \n",
    "            PCA_model = PCA(n_components = n_comps)\n",
    "            PCA_model.fit(scaled_Xtrain)\n",
    "            PCA_Xtrain = PCA_model.transform(scaled_Xtrain)\n",
    "            PCA_Xtest = PCA_model.transform(scaled_Xtest)\n",
    "            \n",
    "            estimator_iter.fit(PCA_Xtrain, ytrain)\n",
    "            \n",
    "            if (estimator_iter.score(PCA_Xtest, ytest) > pca_best_model[estimator][n_comps - 1]):\n",
    "                pca_best_model[estimator][n_comps - 1] = estimator_iter.score(PCA_Xtest, ytest)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"%s - Number of features selected\" % estimator)\n",
    "    plt.ylabel(\"Accuracy score\")\n",
    "    plt.plot(range(1, len(pca_best_model[estimator]) + 1, 1), pca_best_model[estimator], c = 'r')\n",
    "    plt.plot(range(1, len(rfe_best_model[estimator]) + 1, 1), rfe_best_model[estimator], c = 'b')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_best_model_2 = {}\n",
    "pca_best_model_2 = {}\n",
    "\n",
    "rfe_best_model_2['svc'] = []\n",
    "rfe_best_model_2['rfc'] = []\n",
    "rfe_best_model_2['logreg'] = []\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "accuracies['svc'] = [0]\n",
    "accuracies['rfc'] = [0]\n",
    "\n",
    "accuracies['logreg'] = [0]\n",
    "\n",
    "features = {}\n",
    "\n",
    "features['svc'] = []\n",
    "features['rfc'] = []\n",
    "features['logreg'] = []\n",
    "\n",
    "estimator_list = []\n",
    "\n",
    "n_comps = 20\n",
    "                          \n",
    "for i, estimator in enumerate(estimators):\n",
    "    \n",
    "    estimator_list.append(estimator)\n",
    "    model_params = ParameterGrid(params[estimator])\n",
    "    grid = model_params\n",
    "    \n",
    "    rfe_best_model_2[estimator] = []\n",
    "    \n",
    "    rfe_best_model_2[estimator].append(0)\n",
    "    #pca_best_model_2[estimator].append(0)\n",
    "\n",
    "    for params_combo in grid:\n",
    "        estimator_iter = estimators[estimator]\n",
    "        estimator_iter = estimator_iter(**params_combo)\n",
    "\n",
    "        rfe = RFE(estimator = estimator_iter, n_features_to_select=n_comps)\n",
    "        rfe.fit(scaled_Xtrain, ytrain)\n",
    "\n",
    "        if (rfe.score(scaled_Xtest, ytest) > accuracies[estimator][0]):\n",
    "            accuracies[estimator][0] = [rfe.score(scaled_Xtest, ytest)]\n",
    "            features[estimator] = rfe.support_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "est_columns = ['SVC','RFC','Log_Reg'] \n",
    "est_index = ['feature_%d'%i for i in range(0,len(features['svc']))]\n",
    "\n",
    "# display format as scientific \n",
    "pd.options.display.float_format = '{:,.4g}'.format\n",
    "est_df = pd.DataFrame(index=est_index, columns=est_columns)\n",
    "est_df\n",
    "\n",
    "for i in range(0, len(features['svc'])):\n",
    "    est_df.iloc[i, 0] = features['svc'][i]\n",
    "    est_df.iloc[i, 1] = features['rfc'][i]\n",
    "    est_df.iloc[i, 2] = features['logreg'][i]\n",
    "    \n",
    "print('Features used by any Estimator')\n",
    "est_df[est_df['SVC'] | est_df['RFC'] | est_df['Log_Reg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Features used by all Estimators')\n",
    "est_df[est_df['SVC'] & est_df['RFC'] & est_df['Log_Reg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.8, random_state=1234)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=35)\n",
    "\n",
    "rfe = RFE(estimator = rfc, n_features_to_select=20)\n",
    "rfe.fit(Xtrain, ytrain)\n",
    "X_reduced = rfe.transform(X)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_reduced, y, test_size=0.8, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "estimators = {}\n",
    "\n",
    "estimators['svc'] = SVC\n",
    "estimators['rfc'] = RandomForestClassifier\n",
    "estimators['knn'] = KNeighborsClassifier\n",
    "# estimators['logreg'] = LogisticRegression\n",
    "\n",
    "params = {}\n",
    "params['svc'] = {'kernel': ['linear'], 'C': [10**x for x in range(-2, 3, 1)], \n",
    "                 'gamma': [10**x for x in range(-2, 3, 1)], \n",
    "                'random_state': [1234]}\n",
    "params['rfc'] = {'n_estimators': [5*x for x in range(1, 8, 1)]}\n",
    "\n",
    "params['knn'] = {'n_neighbors': range(1, 15, 1), 'p': [1, 2]}\n",
    "# params['logreg'] = {'C': [10**x for x in range(-1, 3, 1)], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "best_model = {}\n",
    "\n",
    "for i, estimator in enumerate(estimators):\n",
    "    model_params = ParameterGrid(params[estimator])\n",
    "    grid = model_params\n",
    "    \n",
    "    best_model[estimator] = [0]\n",
    "    \n",
    "    for params_combo in grid:\n",
    "        \n",
    "        estimator_iter = estimators[estimator]\n",
    "        estimator_iter = estimator_iter(**params_combo)\n",
    "            \n",
    "        estimator_iter.fit(Xtrain, ytrain)\n",
    "        scores = cross_val_score(estimator_iter, Xtrain, ytrain, cv = 10, scoring='accuracy') # smallest class has 2 members\n",
    "        \n",
    "        if (scores.mean() > best_model[estimator][0]):\n",
    "            best_model[estimator] = [scores.mean(), estimator_iter.get_params]\n",
    "\n",
    "    print(\"For %s the best cv accuracy score is %s\" % (estimator, best_model[estimator][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/default_features_1059_tracks.txt', newline='') as inputfile:\n",
    "    data = list(csv.reader(inputfile))\n",
    "    \n",
    "data = np.asarray(data)\n",
    "data.shape\n",
    "\n",
    "y_coords = data[:, 68:70]\n",
    "y_coords = y_coords.astype(dtype = np.float)\n",
    "\n",
    "n_clusters = range(2, 33, 1)\n",
    "\n",
    "accuracies = {'svc':[], 'rfc':[], 'knn':[]}\n",
    "\n",
    "for n in n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n, max_iter = 300, algorithm='full')\n",
    "    kmeans = kmeans.fit(y_coords)\n",
    "    labels = kmeans.predict(y_coords)\n",
    "    \n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(X, labels, test_size=0.8, random_state=1234)\n",
    "\n",
    "    best_model = {}\n",
    "\n",
    "    for i, estimator in enumerate(estimators):\n",
    "        model_params = ParameterGrid(params[estimator])\n",
    "        grid = model_params\n",
    "\n",
    "        best_model[estimator] = [0]\n",
    "        #accuracies[estimator] = []\n",
    "\n",
    "        for params_combo in grid:\n",
    "\n",
    "            estimator_iter = estimators[estimator]\n",
    "            estimator_iter = estimator_iter(**params_combo)\n",
    "\n",
    "            #estimator_iter.fit(Xtrain, ytrain)\n",
    "            scores = cross_val_score(estimator_iter, Xtrain, ytrain, cv = 10, scoring='accuracy') # smallest class has 2 members\n",
    "\n",
    "            if (scores.mean() > best_model[estimator][0]):\n",
    "                best_model[estimator] = [scores.mean(), estimator_iter.get_params]\n",
    "\n",
    "        accuracies[estimator].append(best_model[estimator][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Mean cross validation score\")\n",
    "plt.title(\"Accuracy for different number of location clusters\")\n",
    "plt.plot(range(2, len(accuracies['knn']) + 2),accuracies['knn'], c = 'r')\n",
    "plt.plot(range(2, len(accuracies['svc']) + 2),accuracies['svc'], c = 'b')\n",
    "plt.plot(range(2, len(accuracies['rfc']) + 2),accuracies['rfc'], c = 'g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/default_features_1059_tracks.txt', newline='') as inputfile:\n",
    "    data = list(csv.reader(inputfile))\n",
    "    \n",
    "data = np.asarray(data)\n",
    "data.shape\n",
    "\n",
    "y_coords = data[:, 68:70]\n",
    "y_coords = y_coords.astype(dtype = np.float)\n",
    "\n",
    "n_clusters = 7\n",
    "kmeans = KMeans(n_clusters=n_clusters, max_iter = 500, algorithm='full')\n",
    "kmeans = kmeans.fit(y_coords)\n",
    "labels = kmeans.predict(y_coords)\n",
    "\n",
    "#print('Centroids')\n",
    "centroids = kmeans.cluster_centers_\n",
    "#print(centroids)\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "label_color = [matplotlib.cm.nipy_spectral(float(l) /n_clusters) for l in labels]\n",
    "plt.scatter(y_coords[:, 1], y_coords[:, 0], c = label_color, s=25)\n",
    "plt.title(\"Clustered regions by coordinates\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/default_features_1059_tracks.txt', newline='') as inputfile:\n",
    "    data = list(csv.reader(inputfile))\n",
    "    \n",
    "data = np.asarray(data)\n",
    "data.shape\n",
    "\n",
    "y_coords = data[:, 68:70]\n",
    "y_coords = y_coords.astype(dtype = np.float)\n",
    "\n",
    "n_clusters = 7\n",
    "\n",
    "accuracies = {'svc':[], 'rfc':[], 'knn':[]}\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, max_iter = 300, algorithm='full')\n",
    "kmeans = kmeans.fit(y_coords)\n",
    "labels = kmeans.predict(y_coords)\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X_reduced, labels, test_size=0.8, random_state=1234)\n",
    "\n",
    "best_model = {}\n",
    "\n",
    "for i, estimator in enumerate(estimators):\n",
    "    model_params = ParameterGrid(params[estimator])\n",
    "    grid = model_params\n",
    "\n",
    "    best_model[estimator] = [0]\n",
    "    #accuracies[estimator] = []\n",
    "\n",
    "    for params_combo in grid:\n",
    "\n",
    "        estimator_iter = estimators[estimator]\n",
    "        estimator_iter = estimator_iter(**params_combo)\n",
    "        estimator_iter.fit(Xtrain, ytrain)\n",
    "        #estimator_iter.fit(Xtrain, ytrain)\n",
    "        scores = cross_val_score(estimator_iter, Xtest, ytest, cv = 10, scoring='accuracy') # smallest class has 2 members\n",
    "\n",
    "        if (scores.mean() > best_model[estimator][0]):\n",
    "            best_model[estimator] = [scores.mean(), estimator_iter.get_params, estimator_iter.predict(Xtest)]\n",
    "            best_model[estimator].append(params_combo)\n",
    "\n",
    "    accuracies[estimator].append(best_model[estimator][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_index = ['Accuracy Score', 'parameters', 'parameter values'] \n",
    "acc_columns = ['SVC', 'Random Forest', 'KNN']\n",
    "\n",
    "# display format as scientific \n",
    "pd.options.display.float_format = '{:,.4g}'.format\n",
    "acc_df = pd.DataFrame(index=acc_index, columns=acc_columns)\n",
    "#est_df\n",
    "\n",
    "acc_df.iloc[0, 0] = best_model['svc'][0]\n",
    "acc_df.iloc[0, 1] = best_model['rfc'][0]\n",
    "acc_df.iloc[0, 2] = best_model['knn'][0]\n",
    "acc_df.iloc[1, 0] = list(best_model['svc'][3])\n",
    "acc_df.iloc[1, 1] = list(best_model['rfc'][3])\n",
    "acc_df.iloc[1, 2] = list(best_model['knn'][3])\n",
    "acc_df.iloc[2, 0] = list(best_model['svc'][3].values())\n",
    "acc_df.iloc[2, 1] = list(best_model['rfc'][3].values())\n",
    "acc_df.iloc[2, 2] = list(best_model['knn'][3].values())\n",
    "\n",
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "label_color = [matplotlib.cm.nipy_spectral(float(l) /n_clusters) for l in best_model['svc'][2]]\n",
    "plt.scatter(y_coords[:, 1], y_coords[:, 0], c = label_color, s=25)\n",
    "plt.title(\"Clustered regions by SVC classification (Accuracy score: %s)\" % best_model['svc'][0])\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "label_color = [matplotlib.cm.nipy_spectral(float(l) /n_clusters) for l in best_model['knn'][2]]\n",
    "plt.scatter(y_coords[:, 1], y_coords[:, 0], c = label_color, s=25)\n",
    "plt.title(\"Clustered regions by KNN classification (Accuracy score: %s)\" % best_model['knn'][0])\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "label_color = [matplotlib.cm.nipy_spectral(float(l) /n_clusters) for l in best_model['rfc'][2]]\n",
    "plt.scatter(y_coords[:, 1], y_coords[:, 0], c = label_color, s=25)\n",
    "plt.title(\"Clustered regions by Random Forest classification (Accuracy score: %s)\" % best_model['rfc'][0])\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "results_columns = ['Geo', 'SVC','RFC','KNN'] \n",
    "results_index = ['obs_%d'%i for i in range(0,len(best_model['svc'][2]))]\n",
    "\n",
    "# display format as scientific \n",
    "pd.options.display.float_format = '{:,.4g}'.format\n",
    "results_df = pd.DataFrame(index=results_index, columns=results_columns)\n",
    "results_df\n",
    "\n",
    "for i in range(0, len(best_model['svc'][2])):\n",
    "    results_df.iloc[i, 0] = ytest[i]\n",
    "    results_df.iloc[i, 1] = best_model['svc'][2][i]\n",
    "    results_df.iloc[i, 2] = best_model['rfc'][2][i]\n",
    "    results_df.iloc[i, 3] = best_model['knn'][2][i]\n",
    "    \n",
    "correct_columns = ['SVC', 'RFC', 'KNN']\n",
    "correct_index = ['Correct', 'Incorrect']\n",
    "\n",
    "pd.options.display.float_format = '{:,.4g}'.format\n",
    "correct_df = pd.DataFrame(index=correct_index, columns=correct_columns)\n",
    "correct_df\n",
    "\n",
    "for i in range(0, 3, 1):\n",
    "    correct_df.iloc[0, i] = len(results_df[results_df['Geo'] == results_df.iloc[:, i+1]])\n",
    "    correct_df.iloc[1, i] = len(results_df[results_df['Geo'] != results_df.iloc[:, i+1]])\n",
    "    \n",
    "correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.ensemble import BaggingClassifier\n",
    "# # from sklearn.ensemble import RidgeClassifier\n",
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# # Create classifiers\n",
    "# seed = 1234\n",
    "# rf = RandomForestClassifier()\n",
    "# et = ExtraTreesClassifier()\n",
    "# knn = KNeighborsClassifier()\n",
    "# svc = SVC()\n",
    "# rg = RidgeClassifier()\n",
    "# clf_array = [rf, et, knn, svc]\n",
    "# for clf in clf_array:\n",
    "#     vanilla_scores = cross_val_score(clf, Xtest, ytest, cv=10, n_jobs=-1)\n",
    "#     bagging_clf = BaggingClassifier(clf,max_samples=0.4, max_features=10, random_state=seed)\n",
    "#     bagging_scores = cross_val_score(bagging_clf, X, y, cv=10,n_jobs=-1)\n",
    "    \n",
    "#     print (\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [{0}]\".format(clf.__class__.__name__, vanilla_scores.mean(), vanilla_scores.std()))\n",
    "#     print (\"Mean of: {1:.3f}, std: (+/-) {2:.3f} [Bagging {0}]\\n\".format(clf.__class__.__name__,bagging_scores.mean(), bagging_scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "kfold = model_selection.KFold(n_splits=20,random_state=10)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 200\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=10)\n",
    "results = model_selection.cross_val_score(model, Xtest, ytest, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
